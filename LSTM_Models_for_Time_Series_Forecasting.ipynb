{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Models for Time Series Forecasting",
      "provenance": [],
      "authorship_tag": "ABX9TyPsWHzRL2X/mkW7QJkjT5ZX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadhil96/LSTM_Models_for_Time_Series_Forecasting/blob/main/LSTM_Models_for_Time_Series_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xrUpvWgpnty"
      },
      "source": [
        "# **Univariate LSTM Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQKj_opupLhd"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Bidirectional\r\n",
        "from keras.layers import TimeDistributed\r\n",
        "from keras.layers.convolutional import Conv1D\r\n",
        "from keras.layers.convolutional import MaxPooling1D\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.layers import ConvLSTM2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdyFKrx2pQdU"
      },
      "source": [
        "# split a univariate sequence into samples\r\n",
        "def split_sequence(sequence, n_steps):\r\n",
        "\tX, y = list(), list()\r\n",
        "\tfor i in range(len(sequence)):\r\n",
        "\t\t# find the end of this pattern\r\n",
        "\t\tend_ix = i + n_steps\r\n",
        "\t\t# check if we are beyond the sequence\r\n",
        "\t\tif end_ix > len(sequence)-1:\r\n",
        "\t\t\tbreak\r\n",
        "\t\t# gather input and output parts of the pattern\r\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\r\n",
        "\t\tX.append(seq_x)\r\n",
        "\t\ty.append(seq_y)\r\n",
        "\treturn array(X), array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kLC-g5Wpd63",
        "outputId": "bcbd85d9-74d0-436c-902c-b976dbc8faa0"
      },
      "source": [
        "from numpy import array\r\n",
        "# define input sequence\r\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\r\n",
        "# choose a number of time steps\r\n",
        "n_steps = 3\r\n",
        "# split into samples\r\n",
        "X, y = split_sequence(raw_seq, n_steps)\r\n",
        "# summarize the data\r\n",
        "for i in range(len(X)):\r\n",
        "\tprint(X[i], y[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10 20 30] 40\n",
            "[20 30 40] 50\n",
            "[30 40 50] 60\n",
            "[40 50 60] 70\n",
            "[50 60 70] 80\n",
            "[60 70 80] 90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiuiuWbIqpdA"
      },
      "source": [
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\r\n",
        "n_features = 1\r\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVCUGcZWqrjo",
        "outputId": "ea6a9600-7966-4684-87ce-3152d98fb067"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[10],\n",
              "        [20],\n",
              "        [30]],\n",
              "\n",
              "       [[20],\n",
              "        [30],\n",
              "        [40]],\n",
              "\n",
              "       [[30],\n",
              "        [40],\n",
              "        [50]],\n",
              "\n",
              "       [[40],\n",
              "        [50],\n",
              "        [60]],\n",
              "\n",
              "       [[50],\n",
              "        [60],\n",
              "        [70]],\n",
              "\n",
              "       [[60],\n",
              "        [70],\n",
              "        [80]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeaqC-2cuv8q"
      },
      "source": [
        "# **Vanilla LSTM**\r\n",
        "\r\n",
        "A Vanilla LSTM is an LSTM model that has a single hidden layer of LSTM units, and an output layer used to make a prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfnmFLQPurCI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zB_QeZWpm7y"
      },
      "source": [
        "# define model\r\n",
        "model = Sequential()\r\n",
        "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\r\n",
        "model.add(Dense(1))\r\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-xi2C2hq8au",
        "outputId": "580af910-f0db-4d35-ec5f-981e9126a8b6"
      },
      "source": [
        "# fit model\r\n",
        "model.fit(X, y, epochs=200, verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4881959cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_TNO9jtrwao"
      },
      "source": [
        "# demonstrate prediction\r\n",
        "x_input = array([70, 80, 90])\r\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\r\n",
        "yhat = model.predict(x_input, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIfAoG-4r3EP",
        "outputId": "07c855d8-1c30-4ccb-e1d2-0fb803420f04"
      },
      "source": [
        "yhat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[102.6528]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWaWVjJSsdn4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrGydH4_uDf_"
      },
      "source": [
        "# **Stacked LSTM**\r\n",
        "\r\n",
        "Multiple hidden LSTM layers can be stacked one on top of another in what is referred to as a Stacked LSTM model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFlcSpDWr7Zd"
      },
      "source": [
        "# define model\r\n",
        "model = Sequential()\r\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\r\n",
        "model.add(LSTM(50, activation='relu'))\r\n",
        "model.add(Dense(1))\r\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9_J2hIssDEK",
        "outputId": "d9c476bf-c811-45ba-ee97-c62f81d2b528"
      },
      "source": [
        "# fit model\r\n",
        "model.fit(X, y, epochs=200, verbose=0)\r\n",
        "# demonstrate prediction\r\n",
        "x_input = array([70, 80, 90])\r\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\r\n",
        "yhat = model.predict(x_input, verbose=0)\r\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[103.97407]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSGnWiXWultm"
      },
      "source": [
        "# **Bidirectional LSTM**\r\n",
        "\r\n",
        "On some sequence prediction problems, it can be beneficial to allow the LSTM model to learn the input sequence both forward and backwards and concatenate both interpretations.\r\n",
        "\r\n",
        "This is called a Bidirectional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09nYL_nQuk1n"
      },
      "source": [
        "# define model\r\n",
        "model = Sequential()\r\n",
        "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\r\n",
        "model.add(Dense(1))\r\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwKbqd3uvCUB",
        "outputId": "e9a355b2-098d-4dd7-de71-5ee1f6d2755b"
      },
      "source": [
        "# fit model\r\n",
        "model.fit(X, y, epochs=200, verbose=0)\r\n",
        "# demonstrate prediction\r\n",
        "x_input = array([70, 80, 90])\r\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\r\n",
        "yhat = model.predict(x_input, verbose=0)\r\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[101.136185]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF8gNQmZNrD1"
      },
      "source": [
        "# **CNN LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_pnWFKUMuBW"
      },
      "source": [
        "n_steps = 4\r\n",
        "# split into samples\r\n",
        "X, y = split_sequence(raw_seq, n_steps)\r\n",
        "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\r\n",
        "n_features = 1\r\n",
        "n_seq = 2\r\n",
        "n_steps = 2\r\n",
        "X = X.reshape((X.shape[0], n_seq, n_steps, n_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8AN-ysoNDX2"
      },
      "source": [
        "# define model\r\n",
        "model = Sequential()\r\n",
        "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\r\n",
        "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\r\n",
        "model.add(TimeDistributed(Flatten()))\r\n",
        "model.add(LSTM(50, activation='relu'))\r\n",
        "model.add(Dense(1))\r\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enk6Wv84NjJN",
        "outputId": "1269439e-79f0-40f0-d03d-00f8b64fc779"
      },
      "source": [
        "# fit model\r\n",
        "model.fit(X, y, epochs=500, verbose=0)\r\n",
        "# demonstrate prediction\r\n",
        "x_input = array([60, 70, 80, 90])\r\n",
        "x_input = x_input.reshape((1, n_seq, n_steps, n_features))\r\n",
        "yhat = model.predict(x_input, verbose=0)\r\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[100.85163]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4EGifu4RpPV"
      },
      "source": [
        "# **ConvLSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-aNJJOkNlbq"
      },
      "source": [
        "# choose a number of time steps\r\n",
        "n_steps = 4\r\n",
        "# split into samples\r\n",
        "X, y = split_sequence(raw_seq, n_steps)\r\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\r\n",
        "n_features = 1\r\n",
        "n_seq = 2\r\n",
        "n_steps = 2\r\n",
        "X = X.reshape((X.shape[0], n_seq, 1, n_steps, n_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxoapnkaR4UO",
        "outputId": "e866462c-26d2-4c05-f30f-6c60a5126116"
      },
      "source": [
        "# define model\r\n",
        "model = Sequential()\r\n",
        "model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_steps, n_features)))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(1))\r\n",
        "model.compile(optimizer='adam', loss='mse')\r\n",
        "# fit model\r\n",
        "model.fit(X, y, epochs=500, verbose=0)\r\n",
        "# demonstrate prediction\r\n",
        "x_input = array([60, 70, 80, 90])\r\n",
        "x_input = x_input.reshape((1, n_seq, 1, n_steps, n_features))\r\n",
        "yhat = model.predict(x_input, verbose=0)\r\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f487b5c37a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[104.25437]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUpDnvIMSBbI"
      },
      "source": [
        "# **Multivariate LSTM Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVLJegGfSKrm"
      },
      "source": [
        "# **Multiple Input Series**\r\n",
        "\r\n",
        "A problem may have two or more parallel input time series and an output time series that is dependent on the input time series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2SR26imSdl6"
      },
      "source": [
        "from numpy import hstack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foYfyoOESafB",
        "outputId": "ce94256a-03c5-497d-f105-0d156b01de90"
      },
      "source": [
        " # split a multivariate sequence into samples\r\n",
        "def split_sequences(sequences, n_steps):\r\n",
        "\tX, y = list(), list()\r\n",
        "\tfor i in range(len(sequences)):\r\n",
        "\t\t# find the end of this pattern\r\n",
        "\t\tend_ix = i + n_steps\r\n",
        "\t\t# check if we are beyond the dataset\r\n",
        "\t\tif end_ix > len(sequences):\r\n",
        "\t\t\tbreak\r\n",
        "\t\t# gather input and output parts of the pattern\r\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\r\n",
        "\t\tX.append(seq_x)\r\n",
        "\t\ty.append(seq_y)\r\n",
        "\treturn array(X), array(y)\r\n",
        " \r\n",
        "# define input sequence\r\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\r\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\r\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\r\n",
        "# convert to [rows, columns] structure\r\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\r\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\r\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\r\n",
        "# horizontally stack columns\r\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\r\n",
        "# choose a number of time steps\r\n",
        "n_steps = 3\r\n",
        "# convert into input/output\r\n",
        "X, y = split_sequences(dataset, n_steps)\r\n",
        "print(X.shape, y.shape)\r\n",
        "# summarize the data\r\n",
        "for i in range(len(X)):\r\n",
        "\tprint(X[i], y[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7, 3, 2) (7,)\n",
            "[[10 15]\n",
            " [20 25]\n",
            " [30 35]] 65\n",
            "[[20 25]\n",
            " [30 35]\n",
            " [40 45]] 85\n",
            "[[30 35]\n",
            " [40 45]\n",
            " [50 55]] 105\n",
            "[[40 45]\n",
            " [50 55]\n",
            " [60 65]] 125\n",
            "[[50 55]\n",
            " [60 65]\n",
            " [70 75]] 145\n",
            "[[60 65]\n",
            " [70 75]\n",
            " [80 85]] 165\n",
            "[[70 75]\n",
            " [80 85]\n",
            " [90 95]] 185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVVsMXDsSEaq",
        "outputId": "93706ffe-7e88-41e2-e788-e74232b72ee1"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 3, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUSj24KmTfsW"
      },
      "source": [
        "n_steps = 3\r\n",
        "n_features = X.shape[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79jxmtgeTf2d"
      },
      "source": [
        "# **Vanilla LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7Zz87E7SfgN",
        "outputId": "7e814a3f-275b-4dac-c201-200f34c69503"
      },
      "source": [
        "n_steps = 3\r\n",
        "# convert into input/output\r\n",
        "X, y = split_sequences(dataset, n_steps)\r\n",
        "# the dataset knows the number of features, e.g. 2\r\n",
        "n_features = X.shape[2]\r\n",
        "# define model\r\n",
        "model = Sequential()\r\n",
        "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\r\n",
        "model.add(Dense(1))\r\n",
        "model.compile(optimizer='adam', loss='mse')\r\n",
        "# fit model\r\n",
        "model.fit(X, y, epochs=200, verbose=0)\r\n",
        "# demonstrate prediction\r\n",
        "x_input = array([[80, 85], [90, 95], [100, 105]])\r\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\r\n",
        "yhat = model.predict(x_input, verbose=0)\r\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4880d99e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[206.85767]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4qIYLRnUu4t"
      },
      "source": [
        "# **Multiple Parallel Series**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIkgfLuVSj8h",
        "outputId": "1bdc52e7-ea7c-4d81-b15c-815d5a4e180e"
      },
      "source": [
        " \r\n",
        "# split a multivariate sequence into samples\r\n",
        "def split_sequences(sequences, n_steps):\r\n",
        "\tX, y = list(), list()\r\n",
        "\tfor i in range(len(sequences)):\r\n",
        "\t\t# find the end of this pattern\r\n",
        "\t\tend_ix = i + n_steps\r\n",
        "\t\t# check if we are beyond the dataset\r\n",
        "\t\tif end_ix > len(sequences)-1:\r\n",
        "\t\t\tbreak\r\n",
        "\t\t# gather input and output parts of the pattern\r\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\r\n",
        "\t\tX.append(seq_x)\r\n",
        "\t\ty.append(seq_y)\r\n",
        "\treturn array(X), array(y)\r\n",
        " \r\n",
        "# define input sequence\r\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\r\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\r\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\r\n",
        "# convert to [rows, columns] structure\r\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\r\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\r\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\r\n",
        "# horizontally stack columns\r\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\r\n",
        "# choose a number of time steps\r\n",
        "n_steps = 3\r\n",
        "# convert into input/output\r\n",
        "X, y = split_sequences(dataset, n_steps)\r\n",
        "# the dataset knows the number of features, e.g. 2\r\n",
        "n_features = X.shape[2]\r\n",
        "# define model\r\n",
        "model = Sequential()\r\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\r\n",
        "model.add(LSTM(100, activation='relu'))\r\n",
        "model.add(Dense(n_features))\r\n",
        "model.compile(optimizer='adam', loss='mse')\r\n",
        "# fit model\r\n",
        "model.fit(X, y, epochs=400, verbose=0)\r\n",
        "# demonstrate prediction\r\n",
        "x_input = array([[70,75,145], [80,85,165], [90,95,185]])\r\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\r\n",
        "yhat = model.predict(x_input, verbose=0)\r\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f487b658320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[100.450554 106.281166 205.80305 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7qlH7fAVNhV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgXEe3dWS0I-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sdkj7vK7S2YU",
        "outputId": "4f9fbf88-050e-4eee-dccb-e8028cb415c8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTZhuqxmTFt8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}